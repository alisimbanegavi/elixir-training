- Enables data validation and persistence in Elixir ecosystem
- Phoenix uses Ecto to provide builtin support to the following databases:
    - PostgreSQL (via 'postgrex') 
        - Note: newly generated Phoenix projects include Ecto with the PostgreSQL adapter by default
        - Can pass the --database option to change or --no-ecto flag to exclude this
    - MySQL (via 'myxql')
    - MSSQL (via 'tds')

SCHEMA & MIGRATION GENERATOR---------------------------------------------------------------------------------------------
- Easiest way to use Ecto is to generate an Ecto schema through the 'phx.gen.schema' task
- Ecto schemas are a way for us to specify how Elixir data types map to and from external sources, such as database tables

Ex) User schema with name, email, bio, and number_of_pets fields

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> (divider to denote terminal code)
$ mix phx.gen.schema User users name:string email:string \ bio:string number_of_pets:integer
 
    * creating ./lib/hello/user.ex
    * creating priv/repo/migrations/20170523151118_create_users.exs

Remember to update your repository by running migrations:

   $ mix ecto.migrate
/>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

    - 'user.ex' contains our Ecto schema with our schema definition of the fields we passed to the task
    - 'migrations/...' is a migration file that will create the database table our schema maps to
    - Running our migration:

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
$ mix ecto.migrate
Compiling 1 file (.ex)
Generated hello app

[info]  == Running Hello.Repo.Migrations.CreateUsers.change/0 forward

[info]  create table users

[info]  == Migrated in 0.0s
/>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

- Mix assumes that we are in the development environment unless we tell it otherwise with MIX_ENV=prod mix ecto.migrate
- If we log in to our database server, and connect to our hello_dev database, we should see our users table
- Ecto assumes that we want an integer column called id as our primary key, so we should see a sequence generated for that as well

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
$ psql -U postgres

Type "help" for help.

postgres=# \connect hello_dev
You are now connected to database "hello_dev" as user "postgres".
hello_dev=# \d
                List of relations
 Schema |       Name        |   Type   |  Owner
--------+-------------------+----------+----------
 public | schema_migrations | table    | postgres
 public | users             | table    | postgres
 public | users_id_seq      | sequence | postgres
(3 rows)
hello_dev=# \q
/>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

- Migration generated by phx.gen.schema is in priv/repo/migrations
- If we look at it, we'll see that it adds the columns we specified
- Also adds timestamp columns for inserted_at and updated_at (from timestamps/0 function):

    defmodule Hello.Repo.Migrations.CreateUsers do
    use Ecto.Migration

    def change do
        create table(:users) do
        add :name, :string
        add :email, :string
        add :bio, :string
        add :number_of_pets, :integer

        timestamps()
        end

    end
    end

- Here is what module above translates to in the actual users table:

hello_dev=# \d users
Table "public.users"
Column         |            Type             | Modifiers
---------------+-----------------------------+----------------------------------------------------
id             | integer                     | not null default nextval('users_id_seq'::regclass)
name           | character varying(255)      |
email          | character varying(255)      |
bio            | character varying(255)      |
number_of_pets | integer                     |
inserted_at    | timestamp without time zone | not null
updated_at     | timestamp without time zone | not null
Indexes:
"users_pkey" PRIMARY KEY, btree (id)

REPO CONFIGURATION---------------------------------------------------------------------------------------------
- Hello.Repo module is the foundation needed to work with databases in a Phoenix app
- Generated by Phoenix in lib/hello/repo.ex

    defmodule Hello.Repo do
    use Ecto.Repo,
        otp_app: :hello,
        adapter: Ecto.Adapters.Postgres
    end

- Our repo has 3 main tasks
    - Bring in all the common query functions from Ecto.Repo
    - Set the otp_app name equal to our application name
    - Configure our database adapter (Postgres in this case)

- phx.new generated our app with configuration info (username, password, database, hostname) in config/dev/exs:
    ...
    # Configure your database
    config :hello, Hello.Repo,
    username: "postgres",
    password: "postgres",
    database: "hello_dev",
    hostname: "localhost",
    pool_size: 10
    ...
- These must change if the credentials don't match
- Similar configurations in config/test.exs and config/prod.secret.exs which can also be changed to match actual credentials

THE SCHEMA---------------------------------------------------------------------------------------------
- Ecto schemas are responsible for
    - Mapping Elixir values to external data sources
    - Mapping external data back into Elixir data-structure
- These schemas at their core are simply Elixir structs

- User schema generated for us by Phoenix:

    defmodule Hello.User do
        use Ecto.Schema
        import Ecto.Changeset
        alias Hello.User


        schema "users" do
            field :bio, :string
            field :email, :string
            field :name, :string
            field :number_of_pets, :integer

            timestamps()
        end

        @doc false
        def changeset(%User{} = user, attrs) do
            user
            |> cast(attrs, [:name, :email, :bio, :number_of_pets])
            |> validate_required([:name, :email, :bio, :number_of_pets])
        end
    end

    - Our schema block is what tells Ecto how to cast our %User{} struct fields to and from the external users table

CHANGESETS & VALIDATION---------------------------------------------------------------------------------------------
- Changesets define a pipeline of transformations our data needs to undergo before it will be ready for our application to use
- Could include type-casting, user input validation, and filtering out any extraneous parameters

- Default changeset function:
    def changeset(%User{} = user, attrs) do
        user
        |> cast(attrs, [:name, :email, :bio, :number_of_pets])
        |> validate_required([:name, :email, :bio, :number_of_pets])
    end

    - Ecto.Changeset.cast/3 
        - Passes in our external parameters and marks which fields are required for validation
        - First takes a struct, then the parameters (the proposed updates), and then the final field is the list of columns to be updated
        - Will only take fields that exist in the schema.
    - Ecto.Changeset.validate_required/3
        - Checks that this list of fields is present in the changeset that cast/3 returns
        - By default with the generator, all fields are required

- Building a changeset from our schema with an empty User struct, and an empty map of parameters:
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
iex(1)> alias Hello.User
    Hello.User

iex(2)> changeset = User.changeset(%User{}, %{})
    #Ecto.Changeset<action: nil, changes: %{},
    errors: [name: {"can't be blank", [validation: :required]},
    email: {"can't be blank", [validation: :required]},
    bio: {"can't be blank", [validation: :required]},
    number_of_pets: {"can't be blank", [validation: :required]}],
    data: #Hello.User<>, valid?: false>

    - To see why our changeset is invalid, we can check why with changeset.errors

iex(3)> changeset.errors
    [name: {"can't be blank", [validation: :required]},
    email: {"can't be blank", [validation: :required]},
    bio: {"can't be blank", [validation: :required]},
    number_of_pets: {"can't be blank", [validation: :required]}]
/>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

- Creating a new changeset with a new params map
    - If we pass a key/value pair that isn't defined in the schema/required with this map, it won't make the changeset invalid
- 'changeset.changes' returns the map we get after all the transformations have been completed

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
iex(1)> params = %{name: "Joe Example", email: "joe@example.com", bio: "An example to all", number_of_pets: 5, random_key: "random value"}
    %{email: "joe@example.com", name: "Joe Example", bio: "An example to all",
    number_of_pets: 5, random_key: "random value"}

iex(2)> changeset = User.changeset(%User{}, params)
    #Ecto.Changeset<action: nil,
    changes: %{bio: "An example to all", email: "joe@example.com",
    name: "Joe Example", number_of_pets: 5}, errors: [],
    data: #Hello.User<>, valid?: true>
/>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

- We can also do validation checks for a ton of things besides required input
- This is done by simply adding another transformation to the pipeline in our changeset

Ex) validate_length/2 - Setting min & max length for bio
    validate_format/2 - Checking for the presence of '@' in email

    def changeset(%User{} = user, attrs) do
        user
        |> cast(attrs, [:name, :email, :bio, :number_of_pets])
        |> validate_required([:name, :email, :bio, :number_of_pets])
        |> validate_length(:bio, min: 2)
        |> validate_length(:bio, max: 140)
        |> validate_format(:email, ~r/@/)
    end

    - Checking on the email and bio parameters with changeset.errors
    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    iex(1)> changeset = User.changeset(%User{}, %{bio: "A"})
    iex(2)> changeset.errors[:bio]
        {"should be at least %{count} character(s)",
        [count: 2, validation: :length, min: 2]}
    
    iex(3)> changeset = User.changeset(%User{}, %{email: "example.com"})
    iex(4)> changeset.errors[:email]
        {"has invalid format", [validation: :format]}
    />>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

DATA PERSISTENCE---------------------------------------------------------------------------------------------
- Ecto Repos are the interface into a storage system (lib/hello/repo.ex)
- Repo module's purpose is to take care of the finer details of persistence and data querying for us

Ex) Inserting new users:
    - We start by aliasing User and Repo modules for easy access
    - We then call Repo.insert/1 and pass a user struct
    - We receive a 2-tuple back with {:ok, %User{}}, which lets us know the insertion was successful
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
iex(1)> alias Hello.{Repo, User}
    [Hello.Repo, Hello.User]

iex(2)> Repo.insert(%User{email: "user1@example.com"})
    [debug] QUERY OK db=3.0ms decode=1.1ms queue=4.2ms idle=1290.9ms
    INSERT INTO "users" ("email","inserted_at","updated_at") VALUES ($1,$2,$3) RETURNING "id" ["user1@example.com", ~N[2021-08-18 19:43:49], ~N[2021-08-18 19:43:49]]
    {:ok,
    %Hello.User{
        __meta__: #Ecto.Schema.Metadata<:loaded, "users">,
        bio: nil,
        email: "user1@example.com",
        id: 1,
        inserted_at: ~N[2021-08-18 19:43:49],
        name: nil,
        number_of_pets: nil,
        updated_at: ~N[2021-08-18 19:43:49]
    }}

iex(3)> Repo.insert(%User{email: "user2@example.com"})
    [debug] QUERY OK db=0.9ms idle=1745.3ms
    INSERT INTO "users" ("email","inserted_at","updated_at") VALUES ($1,$2,$3) RETURNING "id" ["user2@example.com", ~N[2021-08-18 19:43:59], ~N[2021-08-18 19:43:59]]
    {:ok,
    %Hello.User{
        __meta__: #Ecto.Schema.Metadata<:loaded, "users">,
        bio: nil,
        email: "user2@example.com",
        id: 2,
        inserted_at: ~N[2021-08-18 19:43:59],
        name: nil,
        number_of_pets: nil,
        updated_at: ~N[2021-08-18 19:43:59]
    }}
/>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

    - After inserting our new users. we can call Repo.all/1 to fetch them all out of the repo
    - Repo.all/1 accepts a data source (our User schema in this case) then translates that to an underlying SQL query against our database
    - Repo then uses our Ecto schema to map the database values back into Elixir data-structures according to our User schema

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
iex(4)> Repo.all(User)
    [debug] QUERY OK source="users" db=6.4ms queue=1.1ms idle=1427.3ms
    SELECT u0."id", u0."bio", u0."email", u0."name", u0."number_of_pets", u0."inserted_at", u0."updated_at" FROM "users" AS u0 []
    [
        %Hello.User{
            __meta__: #Ecto.Schema.Metadata<:loaded, "users">,
            bio: nil,
            email: "user1@example.com",
            id: 1,
            inserted_at: ~N[2021-08-18 19:43:49],
            name: nil,
            number_of_pets: nil,
            updated_at: ~N[2021-08-18 19:43:49]
        },
        %Hello.User{
            __meta__: #Ecto.Schema.Metadata<:loaded, "users">,
            bio: nil,
            email: "user2@example.com",
            id: 2,
            inserted_at: ~N[2021-08-18 19:43:59],
            name: nil,
            number_of_pets: nil,
            updated_at: ~N[2021-08-18 19:43:59]
        }
    ]
/>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>